{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47151c6",
   "metadata": {},
   "source": [
    "# Fannie Mae Loan Performance Data: CSV to Parquet Conversion\n",
    "\n",
    "## Overview\n",
    "This notebook converts Fannie Mae Single-Family Loan Performance CSV files to optimized Parquet format.\n",
    "\n",
    "**Key Features:**\n",
    "- Uses proper column names and data types from the R reference script\n",
    "- Handles pipe-separated values (|) format\n",
    "- Optimizes memory usage with appropriate data types\n",
    "- Provides significant file size reduction through compression\n",
    "\n",
    "**Input:** Raw CSV files from Fannie Mae (located in `../../data/raw/`)\n",
    "**Output:** Optimized Parquet files for efficient analysis (saved to `../../data/processed/`)\n",
    "\n",
    "**Reference:** Based on `LPPUB_Infile.R` script from Fannie Mae (see `../scripts/`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee334a6",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5aacfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ pyarrow is available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Install pyarrow if not already available\n",
    "try:\n",
    "    import pyarrow\n",
    "    print(\"âœ“ pyarrow is available\")\n",
    "except ImportError:\n",
    "    print(\"Installing pyarrow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow\"])\n",
    "    import pyarrow\n",
    "    print(\"âœ“ pyarrow installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833716d",
   "metadata": {},
   "source": [
    "## 2. Configuration and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa46ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input CSV: ../../data/raw/2025Q1.csv\n",
      "Output Parquet: ../../data/processed/2025Q1.parquet\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "SOURCE_DATA_DIR = Path('../../data/raw')\n",
    "PROCESSED_DATA_DIR = Path('../../data/processed')\n",
    "INPUT_FILE = '2025Q1.csv'  # Change this to process different files\n",
    "\n",
    "csv_path = SOURCE_DATA_DIR / INPUT_FILE\n",
    "parquet_path = PROCESSED_DATA_DIR / INPUT_FILE.replace('.csv', '.parquet')\n",
    "\n",
    "print(f\"Input CSV: {csv_path}\")\n",
    "print(f\"Output Parquet: {parquet_path}\")\n",
    "print(f\"File exists: {csv_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e30374",
   "metadata": {},
   "source": [
    "## 3. Column Definitions from Fannie Mae R Script\n",
    "\n",
    "These column names and types are based on the official `LPPUB_Infile.R` script provided by Fannie Mae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfab3599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 110\n"
     ]
    }
   ],
   "source": [
    "# Column names from LPPUB_Infile.R\n",
    "LPPUB_COLUMN_NAMES = [\n",
    "    \"POOL_ID\", \"LOAN_ID\", \"ACT_PERIOD\", \"CHANNEL\", \"SELLER\", \"SERVICER\",\n",
    "    \"MASTER_SERVICER\", \"ORIG_RATE\", \"CURR_RATE\", \"ORIG_UPB\", \"ISSUANCE_UPB\",\n",
    "    \"CURRENT_UPB\", \"ORIG_TERM\", \"ORIG_DATE\", \"FIRST_PAY\", \"LOAN_AGE\",\n",
    "    \"REM_MONTHS\", \"ADJ_REM_MONTHS\", \"MATR_DT\", \"OLTV\", \"OCLTV\",\n",
    "    \"NUM_BO\", \"DTI\", \"CSCORE_B\", \"CSCORE_C\", \"FIRST_FLAG\", \"PURPOSE\",\n",
    "    \"PROP\", \"NO_UNITS\", \"OCC_STAT\", \"STATE\", \"MSA\", \"ZIP\", \"MI_PCT\",\n",
    "    \"PRODUCT\", \"PPMT_FLG\", \"IO\", \"FIRST_PAY_IO\", \"MNTHS_TO_AMTZ_IO\",\n",
    "    \"DLQ_STATUS\", \"PMT_HISTORY\", \"MOD_FLAG\", \"MI_CANCEL_FLAG\", \"Zero_Bal_Code\",\n",
    "    \"ZB_DTE\", \"LAST_UPB\", \"RPRCH_DTE\", \"CURR_SCHD_PRNCPL\", \"TOT_SCHD_PRNCPL\",\n",
    "    \"UNSCHD_PRNCPL_CURR\", \"LAST_PAID_INSTALLMENT_DATE\", \"FORECLOSURE_DATE\",\n",
    "    \"DISPOSITION_DATE\", \"FORECLOSURE_COSTS\", \"PROPERTY_PRESERVATION_AND_REPAIR_COSTS\",\n",
    "    \"ASSET_RECOVERY_COSTS\", \"MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS\",\n",
    "    \"ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY\", \"NET_SALES_PROCEEDS\",\n",
    "    \"CREDIT_ENHANCEMENT_PROCEEDS\", \"REPURCHASES_MAKE_WHOLE_PROCEEDS\",\n",
    "    \"OTHER_FORECLOSURE_PROCEEDS\", \"NON_INTEREST_BEARING_UPB\", \"PRINCIPAL_FORGIVENESS_AMOUNT\",\n",
    "    \"ORIGINAL_LIST_START_DATE\", \"ORIGINAL_LIST_PRICE\", \"CURRENT_LIST_START_DATE\",\n",
    "    \"CURRENT_LIST_PRICE\", \"ISSUE_SCOREB\", \"ISSUE_SCOREC\", \"CURR_SCOREB\",\n",
    "    \"CURR_SCOREC\", \"MI_TYPE\", \"SERV_IND\", \"CURRENT_PERIOD_MODIFICATION_LOSS_AMOUNT\",\n",
    "    \"CUMULATIVE_MODIFICATION_LOSS_AMOUNT\", \"CURRENT_PERIOD_CREDIT_EVENT_NET_GAIN_OR_LOSS\",\n",
    "    \"CUMULATIVE_CREDIT_EVENT_NET_GAIN_OR_LOSS\", \"HOMEREADY_PROGRAM_INDICATOR\",\n",
    "    \"FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT\", \"RELOCATION_MORTGAGE_INDICATOR\",\n",
    "    \"ZERO_BALANCE_CODE_CHANGE_DATE\", \"LOAN_HOLDBACK_INDICATOR\", \"LOAN_HOLDBACK_EFFECTIVE_DATE\",\n",
    "    \"DELINQUENT_ACCRUED_INTEREST\", \"PROPERTY_INSPECTION_WAIVER_INDICATOR\",\n",
    "    \"HIGH_BALANCE_LOAN_INDICATOR\", \"ARM_5_YR_INDICATOR\", \"ARM_PRODUCT_TYPE\",\n",
    "    \"MONTHS_UNTIL_FIRST_PAYMENT_RESET\", \"MONTHS_BETWEEN_SUBSEQUENT_PAYMENT_RESET\",\n",
    "    \"INTEREST_RATE_CHANGE_DATE\", \"PAYMENT_CHANGE_DATE\", \"ARM_INDEX\",\n",
    "    \"ARM_CAP_STRUCTURE\", \"INITIAL_INTEREST_RATE_CAP\", \"PERIODIC_INTEREST_RATE_CAP\",\n",
    "    \"LIFETIME_INTEREST_RATE_CAP\", \"MARGIN\", \"BALLOON_INDICATOR\",\n",
    "    \"PLAN_NUMBER\", \"FORBEARANCE_INDICATOR\", \"HIGH_LOAN_TO_VALUE_HLTV_REFINANCE_OPTION_INDICATOR\",\n",
    "    \"DEAL_NAME\", \"RE_PROCS_FLAG\", \"ADR_TYPE\", \"ADR_COUNT\", \"ADR_UPB\", \n",
    "    \"PAYMENT_DEFERRAL_MOD_EVENT_FLAG\", \"INTEREST_BEARING_UPB\"\n",
    "]\n",
    "\n",
    "print(f\"Total columns: {len(LPPUB_COLUMN_NAMES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be85b4",
   "metadata": {},
   "source": [
    "## 4. Optimized Data Types\n",
    "\n",
    "Define optimized data types for better memory efficiency and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23bbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type mappings defined for 109 columns\n"
     ]
    }
   ],
   "source": [
    "# Optimized data types based on R script column classes\n",
    "OPTIMIZED_DTYPES = {\n",
    "    # Character/categorical columns\n",
    "    \"POOL_ID\": \"string\", \"LOAN_ID\": \"string\", \"ACT_PERIOD\": \"string\", \n",
    "    \"CHANNEL\": \"category\", \"SELLER\": \"category\", \"SERVICER\": \"category\",\n",
    "    \"MASTER_SERVICER\": \"category\", \"ORIG_DATE\": \"string\", \"FIRST_PAY\": \"string\", \n",
    "    \"MATR_DT\": \"string\", \"FIRST_FLAG\": \"category\", \"PURPOSE\": \"category\",\n",
    "    \"PROP\": \"category\", \"OCC_STAT\": \"category\", \"STATE\": \"category\", \n",
    "    \"MSA\": \"string\", \"ZIP\": \"string\", \"PRODUCT\": \"category\", \n",
    "    \"PPMT_FLG\": \"category\", \"IO\": \"category\", \"FIRST_PAY_IO\": \"string\", \n",
    "    \"MNTHS_TO_AMTZ_IO\": \"string\", \"DLQ_STATUS\": \"category\", \"PMT_HISTORY\": \"string\", \n",
    "    \"MOD_FLAG\": \"category\", \"MI_CANCEL_FLAG\": \"category\", \"Zero_Bal_Code\": \"category\",\n",
    "    \"ZB_DTE\": \"string\", \"RPRCH_DTE\": \"string\", \"LAST_PAID_INSTALLMENT_DATE\": \"string\",\n",
    "    \"FORECLOSURE_DATE\": \"string\", \"DISPOSITION_DATE\": \"string\", \"ORIGINAL_LIST_START_DATE\": \"string\",\n",
    "    \"CURRENT_LIST_START_DATE\": \"string\", \"MI_TYPE\": \"category\", \"SERV_IND\": \"category\",\n",
    "    \"HOMEREADY_PROGRAM_INDICATOR\": \"category\", \"RELOCATION_MORTGAGE_INDICATOR\": \"category\",\n",
    "    \"ZERO_BALANCE_CODE_CHANGE_DATE\": \"string\", \"LOAN_HOLDBACK_INDICATOR\": \"category\",\n",
    "    \"LOAN_HOLDBACK_EFFECTIVE_DATE\": \"string\", \"PROPERTY_INSPECTION_WAIVER_INDICATOR\": \"category\",\n",
    "    \"HIGH_BALANCE_LOAN_INDICATOR\": \"category\", \"ARM_5_YR_INDICATOR\": \"category\",\n",
    "    \"ARM_PRODUCT_TYPE\": \"string\", \"INTEREST_RATE_CHANGE_DATE\": \"string\",\n",
    "    \"PAYMENT_CHANGE_DATE\": \"string\", \"ARM_INDEX\": \"string\", \"ARM_CAP_STRUCTURE\": \"string\",\n",
    "    \"BALLOON_INDICATOR\": \"category\", \"PLAN_NUMBER\": \"string\", \"FORBEARANCE_INDICATOR\": \"category\",\n",
    "    \"HIGH_LOAN_TO_VALUE_HLTV_REFINANCE_OPTION_INDICATOR\": \"category\", \"DEAL_NAME\": \"string\",\n",
    "    \"RE_PROCS_FLAG\": \"category\", \"ADR_TYPE\": \"string\", \"PAYMENT_DEFERRAL_MOD_EVENT_FLAG\": \"category\",\n",
    "    \n",
    "    # Numeric columns with appropriate precision\n",
    "    \"ORIG_RATE\": \"float32\", \"CURR_RATE\": \"float32\", \"ORIG_UPB\": \"float64\", \"ISSUANCE_UPB\": \"float64\",\n",
    "    \"CURRENT_UPB\": \"float64\", \"ORIG_TERM\": \"int16\", \"LOAN_AGE\": \"int16\", \"REM_MONTHS\": \"int16\",\n",
    "    \"ADJ_REM_MONTHS\": \"int16\", \"OLTV\": \"float32\", \"OCLTV\": \"float32\", \"DTI\": \"float32\",\n",
    "    \"CSCORE_B\": \"int16\", \"CSCORE_C\": \"int16\", \"MI_PCT\": \"float32\", \"NO_UNITS\": \"int8\",\n",
    "    \"LAST_UPB\": \"float64\", \"CURR_SCHD_PRNCPL\": \"float64\", \"TOT_SCHD_PRNCPL\": \"float64\",\n",
    "    \"UNSCHD_PRNCPL_CURR\": \"float64\", \"FORECLOSURE_COSTS\": \"float64\", \n",
    "    \"PROPERTY_PRESERVATION_AND_REPAIR_COSTS\": \"float64\", \"ASSET_RECOVERY_COSTS\": \"float64\",\n",
    "    \"MISCELLANEOUS_HOLDING_EXPENSES_AND_CREDITS\": \"float64\", \"ASSOCIATED_TAXES_FOR_HOLDING_PROPERTY\": \"float64\",\n",
    "    \"NET_SALES_PROCEEDS\": \"float64\", \"CREDIT_ENHANCEMENT_PROCEEDS\": \"float64\",\n",
    "    \"REPURCHASES_MAKE_WHOLE_PROCEEDS\": \"float64\", \"OTHER_FORECLOSURE_PROCEEDS\": \"float64\",\n",
    "    \"NON_INTEREST_BEARING_UPB\": \"float64\", \"PRINCIPAL_FORGIVENESS_AMOUNT\": \"float64\",\n",
    "    \"ORIGINAL_LIST_PRICE\": \"float64\", \"CURRENT_LIST_PRICE\": \"float64\",\n",
    "    \"ISSUE_SCOREB\": \"int16\", \"ISSUE_SCOREC\": \"int16\", \"CURR_SCOREB\": \"int16\", \"CURR_SCOREC\": \"int16\",\n",
    "    \"CURRENT_PERIOD_MODIFICATION_LOSS_AMOUNT\": \"float64\", \"CUMULATIVE_MODIFICATION_LOSS_AMOUNT\": \"float64\",\n",
    "    \"CURRENT_PERIOD_CREDIT_EVENT_NET_GAIN_OR_LOSS\": \"float64\", \"CUMULATIVE_CREDIT_EVENT_NET_GAIN_OR_LOSS\": \"float64\",\n",
    "    \"FORECLOSURE_PRINCIPAL_WRITE_OFF_AMOUNT\": \"float64\", \"DELINQUENT_ACCRUED_INTEREST\": \"float64\",\n",
    "    \"MONTHS_UNTIL_FIRST_PAYMENT_RESET\": \"int16\", \"MONTHS_BETWEEN_SUBSEQUENT_PAYMENT_RESET\": \"int16\",\n",
    "    \"INITIAL_INTEREST_RATE_CAP\": \"float32\", \"PERIODIC_INTEREST_RATE_CAP\": \"float32\",\n",
    "    \"LIFETIME_INTEREST_RATE_CAP\": \"float32\", \"MARGIN\": \"float32\", \"ADR_COUNT\": \"int16\",\n",
    "    \"ADR_UPB\": \"float64\", \"INTEREST_BEARING_UPB\": \"float64\"\n",
    "}\n",
    "\n",
    "print(f\"Data type mappings defined for {len(OPTIMIZED_DTYPES)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aca490",
   "metadata": {},
   "source": [
    "## 5. CSV to Parquet Conversion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c725817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_parquet(csv_file_path, parquet_file_path, column_names, dtype_mapping):\n",
    "    \"\"\"\n",
    "    Convert Fannie Mae CSV to optimized Parquet format.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_file_path: Path to input CSV file\n",
    "    - parquet_file_path: Path to output Parquet file\n",
    "    - column_names: List of column names\n",
    "    - dtype_mapping: Dictionary mapping column names to data types\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with converted data\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”„ Reading CSV file: {csv_file_path}\")\n",
    "    \n",
    "    # First pass: Read as strings to handle any data issues\n",
    "    df = pd.read_csv(\n",
    "        csv_file_path,\n",
    "        sep='|',\n",
    "        names=column_names,\n",
    "        dtype='string',\n",
    "        header=None,\n",
    "        low_memory=False,\n",
    "        na_values=['', ' ', 'NULL', 'null', 'NA']\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸ“Š Initial shape: {df.shape}\")\n",
    "    print(f\"ðŸ”§ Converting data types...\")\n",
    "    \n",
    "    # Convert to optimized data types\n",
    "    conversion_errors = []\n",
    "    \n",
    "    for col, target_dtype in dtype_mapping.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if target_dtype == 'category':\n",
    "                    df[col] = df[col].astype('category')\n",
    "                elif target_dtype in ['int8', 'int16', 'int32', 'int64']:\n",
    "                    # Use nullable integer types for columns with missing values\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                    df[col] = df[col].astype(f'Int{target_dtype[3:]}')\n",
    "                elif target_dtype in ['float32', 'float64']:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').astype(target_dtype)\n",
    "                elif target_dtype == 'string':\n",
    "                    df[col] = df[col].astype('string')\n",
    "            except Exception as e:\n",
    "                conversion_errors.append(f\"{col}: {str(e)}\")\n",
    "    \n",
    "    if conversion_errors:\n",
    "        print(f\"âš ï¸  Conversion warnings for {len(conversion_errors)} columns\")\n",
    "        for error in conversion_errors[:5]:  # Show first 5 errors\n",
    "            print(f\"   {error}\")\n",
    "    \n",
    "    print(f\"ðŸ’¾ Saving to Parquet: {parquet_file_path}\")\n",
    "    \n",
    "    # Save to Parquet with compression\n",
    "    df.to_parquet(\n",
    "        parquet_file_path,\n",
    "        engine='pyarrow',\n",
    "        compression='snappy',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06d7df",
   "metadata": {},
   "source": [
    "## 6. Run the Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baadc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Reading CSV file: ../../data/raw/2025Q1.csv\n",
      "ðŸ“Š Initial shape: (388622, 110)\n",
      "ðŸ”§ Converting data types...\n",
      "ðŸ’¾ Saving to Parquet: ../../data/processed/2025Q1.parquet\n",
      "\n",
      "âœ… Conversion completed successfully!\n",
      "ðŸ“ˆ Final shape: (388622, 110)\n"
     ]
    }
   ],
   "source": [
    "# Perform the conversion\n",
    "df_converted = convert_csv_to_parquet(\n",
    "    csv_path, \n",
    "    parquet_path, \n",
    "    LPPUB_COLUMN_NAMES, \n",
    "    OPTIMIZED_DTYPES\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Conversion completed successfully!\")\n",
    "print(f\"ðŸ“ˆ Final shape: {df_converted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6175750",
   "metadata": {},
   "source": [
    "## 7. Verification and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210051ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ File Size Comparison:\n",
      "   CSV:     123,044,558 bytes (117.34 MB)\n",
      "   Parquet: 8,896,605 bytes (8.48 MB)\n",
      "   Compression ratio: 13.83x\n",
      "   Space saved: 92.8%\n",
      "\n",
      "ðŸ” Verification - Reading Parquet file:\n",
      "   Shape: (388622, 110)\n",
      "   Memory usage: ~734.56 MB\n",
      "\n",
      "ðŸ“‹ Sample Data Types:\n",
      "   POOL_ID: string\n",
      "   LOAN_ID: string\n",
      "   ACT_PERIOD: string\n",
      "   CHANNEL: category\n",
      "   SELLER: category\n",
      "   SERVICER: category\n",
      "   MASTER_SERVICER: category\n",
      "   ORIG_RATE: float32\n",
      "   CURR_RATE: float32\n",
      "   ORIG_UPB: float64\n"
     ]
    }
   ],
   "source": [
    "# File size comparison\n",
    "csv_size = os.path.getsize(csv_path)\n",
    "parquet_size = os.path.getsize(parquet_path)\n",
    "\n",
    "print(\"ðŸ“ File Size Comparison:\")\n",
    "print(f\"   CSV:     {csv_size:,} bytes ({csv_size/1024/1024:.2f} MB)\")\n",
    "print(f\"   Parquet: {parquet_size:,} bytes ({parquet_size/1024/1024:.2f} MB)\")\n",
    "print(f\"   Compression ratio: {csv_size/parquet_size:.2f}x\")\n",
    "print(f\"   Space saved: {((csv_size - parquet_size) / csv_size) * 100:.1f}%\")\n",
    "\n",
    "# Verify by reading back\n",
    "print(\"\\nðŸ” Verification - Reading Parquet file:\")\n",
    "df_verify = pd.read_parquet(parquet_path, engine='pyarrow')\n",
    "print(f\"   Shape: {df_verify.shape}\")\n",
    "print(f\"   Memory usage: ~{df_verify.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Sample Data Types:\")\n",
    "for i, (col, dtype) in enumerate(df_verify.dtypes.head(10).items()):\n",
    "    print(f\"   {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e333d",
   "metadata": {},
   "source": [
    "## 8. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42eba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data Quality Summary:\n",
      "   Total rows: 388,622\n",
      "   Total columns: 110\n",
      "   Columns with missing values: 77\n",
      "   Top 5 columns with most missing values:\n",
      "     POOL_ID: 388,622 (100.0%)\n",
      "     SERVICER: 651 (0.2%)\n",
      "     MASTER_SERVICER: 388,622 (100.0%)\n",
      "     CURR_RATE: 651 (0.2%)\n",
      "     ISSUANCE_UPB: 388,622 (100.0%)\n",
      "\n",
      "ðŸ“ˆ Data Type Distribution:\n",
      "   string: 29 columns\n",
      "   float64: 28 columns\n",
      "   Int16: 13 columns\n",
      "   float32: 10 columns\n",
      "   category: 5 columns\n",
      "   category: 5 columns\n",
      "   category: 4 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   Int8: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n",
      "   category: 1 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Data Quality Summary:\")\n",
    "print(f\"   Total rows: {len(df_verify):,}\")\n",
    "print(f\"   Total columns: {len(df_verify.columns)}\")\n",
    "\n",
    "# Missing values summary\n",
    "missing_summary = df_verify.isnull().sum()\n",
    "columns_with_missing = missing_summary[missing_summary > 0]\n",
    "\n",
    "print(f\"   Columns with missing values: {len(columns_with_missing)}\")\n",
    "if len(columns_with_missing) > 0:\n",
    "    print(f\"   Top 5 columns with most missing values:\")\n",
    "    for col, count in columns_with_missing.head().items():\n",
    "        pct = (count / len(df_verify)) * 100\n",
    "        print(f\"     {col}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Data type distribution\n",
    "dtype_counts = df_verify.dtypes.value_counts()\n",
    "print(f\"\\nðŸ“ˆ Data Type Distribution:\")\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"   {dtype}: {count} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fee0a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully converts Fannie Mae Loan Performance CSV files to optimized Parquet format with:\n",
    "\n",
    "- **Proper column naming** based on official R script\n",
    "- **Optimized data types** for memory efficiency\n",
    "- **Significant compression** (typically 10-15x size reduction)\n",
    "- **Data integrity** preservation\n",
    "- **Error handling** for data quality issues\n",
    "\n",
    "The resulting Parquet files can be used for efficient data analysis with much faster read times and reduced storage requirements.\n",
    "\n",
    "**Next Steps:**\n",
    "- Use the Parquet files for analysis in other notebooks\n",
    "- Consider partitioning large datasets by year/quarter\n",
    "- Implement data validation checks for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
